{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.dygraph import Conv2D, Pool2D, Linear\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 噪声维度\n",
    "Z_DIM = 100\n",
    "BATCH_SIZE = 128\n",
    "# 读取真实图片的数据集，这里去除了数据集中的label数据，因为label在这里使用不上，这里不考虑标签分类问题。\n",
    "def mnist_reader(reader):\n",
    "    def r():\n",
    "        for img, label in reader():\n",
    "            yield img.reshape(1, 28, 28)\n",
    "    return r\n",
    "\n",
    "# 噪声生成，通过由噪声来生成假的图片数据输入。\n",
    "def z_reader():\n",
    "    while True:\n",
    "        yield np.random.normal(0.0, 1.0, (Z_DIM, 1, 1)).astype('float32')                #正态分布，正态分布的均值、标准差、参数\n",
    "\n",
    "# 生成真实图片reader\n",
    "mnist_generator = paddle.batch(\n",
    "        paddle.reader.shuffle(mnist_reader(paddle.dataset.mnist.train()), 30000),\n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "# 生成假图片的reader\n",
    "z_generator = paddle.batch(z_reader, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pics_tmp = next(mnist_generator())\n",
    "print('一个batch图片数据的形状：batch_size =', len(pics_tmp), ', data_shape =', pics_tmp[0].shape)\n",
    "\n",
    "plt.imshow(pics_tmp[0][0]) # (28,28)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_tmp = next(z_generator())\n",
    "print('一个batch噪声z的形状：batch_size =', len(z_tmp), ', data_shape =', z_tmp[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过上采样扩大特征图\n",
    "class G(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope):\n",
    "        super(G, self).__init__(name_scope)\n",
    "        name_scope = self.full_name()\n",
    "        self.fc1 = Linear(100,1024);\n",
    "        self.bn1 = fluid.dygraph.BatchNorm(num_channels=1024,act='tanh')\n",
    "        self.fc2 = Linear(1024,6272);\n",
    "        self.bn2 = fluid.dygraph.BatchNorm(num_channels=6272,act='tanh')\n",
    "        self.conv1 = Conv2D(num_channels=128,num_filters=64,filter_size=5,padding=2)\n",
    "        self.bn3 = fluid.dygraph.BatchNorm(num_channels=64,act='tanh')\n",
    "        self.conv2 = Conv2D(num_channels=64,num_filters=1,filter_size=5,padding=2,act='tanh')\n",
    "        #self.bn4 = fluid.dygraph.BatchNorm(num_channels=1,act='tanh')\n",
    "\n",
    "        #\n",
    "        # My_G的代码\n",
    "        #\n",
    "        \n",
    "    def forward(self, z):\n",
    "        #\n",
    "        # My_G forward的代码\n",
    "        #\n",
    "        x = fluid.layers.reshape(z,shape=(-1,100));\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = fluid.layers.reshape(x,shape=(-1,128,7,7))\n",
    "        x = fluid.layers.image_resize(x,scale=2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn3(x)\n",
    "        x = fluid.layers.image_resize(x,scale=2)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class D(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope):\n",
    "        super(D, self).__init__(name_scope)\n",
    "        name_scope = self.full_name()\n",
    "        self.conv1 = Conv2D(num_channels=1,num_filters=64,filter_size=3)\n",
    "        self.bn1 = fluid.dygraph.BatchNorm(num_channels=64,act='relu')\n",
    "        self.pool1 = Pool2D(pool_size=2,pool_stride=2)\n",
    "        self.conv2 = Conv2D(num_channels=64,num_filters=128,filter_size=3)\n",
    "        self.bn2 = fluid.dygraph.BatchNorm(num_channels=128,act='relu')\n",
    "        self.pool2 = Pool2D(pool_size=2,pool_stride=2)\n",
    "        self.fc1 = Linear(3200,1024)\n",
    "        self.bn3 = fluid.dygraph.BatchNorm(num_channels=1024,act='relu')\n",
    "        self.fc2 = Linear(1024,1,act='sigmoid')\n",
    "        #\n",
    "        # My_D的代码\n",
    "        #\n",
    "\n",
    "    def forward(self, img):  \n",
    "        #\n",
    "        # My_G forward的代码\n",
    "        #\n",
    "        x = self.conv1(img)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = fluid.layers.reshape(x,shape=(-1,3200))\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试生成网络G和判别网络D\n",
    "with fluid.dygraph.guard():\n",
    "    g_tmp = G('G')\n",
    "    tmp_g = g_tmp(fluid.dygraph.to_variable(np.array(z_tmp))).numpy()\n",
    "    print('生成器G生成图片数据的形状：', tmp_g.shape)\n",
    "    plt.imshow(tmp_g[0][0])\n",
    "    plt.show()\n",
    "    \n",
    "    d_tmp = D('D')\n",
    "    tmp_d = d_tmp(fluid.dygraph.to_variable(tmp_g)).numpy()\n",
    "    print('判别器D判别生成的图片的概率数据形状：', tmp_d.shape)\n",
    "    print(max(tmp_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示图片，构建一个16*n大小(n=batch_size/16)的图片阵列，把预测的图片打印到note中。\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show_image_grid(images, batch_size=128, pass_id=None):\n",
    "    fig = plt.figure(figsize=(8, batch_size/32))\n",
    "    fig.suptitle(\"Pass {}\".format(pass_id))\n",
    "    gs = plt.GridSpec(int(batch_size/16), 16)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(image[0], cmap='Greys_r')    \n",
    "    plt.show()\n",
    "\n",
    "show_image_grid(tmp_g, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mnist_generator, epoch_num=1, batch_size=128, use_gpu=True, load_model=False):\n",
    "    place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\n",
    "    with fluid.dygraph.guard(place):\n",
    "        # 模型存储路径\n",
    "        model_path = './output/'\n",
    "        d = D('D')\n",
    "        d.train()\n",
    "        g = G('G')\n",
    "        g.train()\n",
    "        # 创建优化方法\n",
    "        real_d_optimizer = fluid.optimizer.AdamOptimizer(learning_rate=2e-4, parameter_list=d.parameters())\n",
    "        fake_d_optimizer = fluid.optimizer.AdamOptimizer(learning_rate=2e-4, parameter_list=d.parameters())\n",
    "        g_optimizer = fluid.optimizer.AdamOptimizer(learning_rate=2e-4, parameter_list=g.parameters())\n",
    "        \n",
    "        # 读取上次保存的模型\n",
    "        if load_model == True:\n",
    "            g_para, g_opt = fluid.load_dygraph(model_path+'g')\n",
    "            d_para, d_r_opt = fluid.load_dygraph(model_path+'d_o_r')\n",
    "            # 上面判别器的参数已经读取到d_para了,此处无需再次读取\n",
    "            _, d_f_opt = fluid.load_dygraph(model_path+'d_o_f')\n",
    "            g.load_dict(g_para)\n",
    "            g_optimizer.set_dict(g_opt)\n",
    "            d.load_dict(d_para)\n",
    "            real_d_optimizer.set_dict(d_r_opt)\n",
    "            fake_d_optimizer.set_dict(d_f_opt)\n",
    "\n",
    "        iteration_num = 0\n",
    "        for epoch in range(epoch_num):\n",
    "            for i, real_image in enumerate(mnist_generator()):\n",
    "                # 丢弃不满整个batch_size的数据\n",
    "                if(len(real_image) != BATCH_SIZE):\n",
    "                    continue               \n",
    "                iteration_num += 1                \n",
    "                '''\n",
    "                判别器d通过最小化输入真实图片时判别器d的输出与真值标签ones的交叉熵损失，来优化判别器的参数，\n",
    "                以增加判别器d识别真实图片real_image为真值标签ones的概率。\n",
    "                '''\n",
    "                # 将MNIST数据集里的图片读入real_image，将真值标签ones用数字1初始化\n",
    "                real_image = fluid.dygraph.to_variable(np.array(real_image))\n",
    "                ones = fluid.dygraph.to_variable(np.ones([len(real_image), 1]).astype('float32'))\n",
    "                # 计算判别器d判断真实图片的概率\n",
    "                p_real = d(real_image)\n",
    "                # 计算判别真图片为真的损失\n",
    "                real_cost = fluid.layers.sigmoid_cross_entropy_with_logits(p_real, ones)\n",
    "                real_avg_cost = fluid.layers.mean(real_cost)\n",
    "                # 反向传播更新判别器d的参数\n",
    "                real_avg_cost.backward()\n",
    "                real_d_optimizer.minimize(real_avg_cost)\n",
    "                d.clear_gradients()\n",
    "                \n",
    "                '''\n",
    "                判别器d通过最小化输入生成器g生成的假图片g(z)时判别器的输出与假值标签zeros的交叉熵损失，\n",
    "                来优化判别器d的参数，以增加判别器d识别生成器g生成的假图片g(z)为假值标签zeros的概率。\n",
    "                '''\n",
    "                # 创建高斯分布的噪声z，将假值标签zeros初始化为0\n",
    "                z = next(z_generator())\n",
    "                z = fluid.dygraph.to_variable(np.array(z))\n",
    "                zeros = fluid.dygraph.to_variable(np.zeros([len(real_image), 1]).astype('float32'))\n",
    "                # 判别器d判断生成器g生成的假图片的概率\n",
    "                p_fake = d(g(z))\n",
    "                # 计算判别生成器g生成的假图片为假的损失\n",
    "                fake_cost = fluid.layers.sigmoid_cross_entropy_with_logits(p_fake, zeros)\n",
    "                fake_avg_cost = fluid.layers.mean(fake_cost)\n",
    "                # 反向传播更新判别器d的参数\n",
    "                fake_avg_cost.backward()\n",
    "                fake_d_optimizer.minimize(fake_avg_cost)\n",
    "                d.clear_gradients()\n",
    "\n",
    "                '''\n",
    "                生成器g通过最小化判别器d判别生成器生成的假图片g(z)为真的概率d(fake)与真值标签ones的交叉熵损失，\n",
    "                来优化生成器g的参数，以增加生成器g使判别器d判别其生成的假图片g(z)为真值标签ones的概率。\n",
    "                '''\n",
    "                # 生成器用输入的高斯噪声z生成假图片\n",
    "                fake = g(z)\n",
    "                # 计算判别器d判断生成器g生成的假图片的概率\n",
    "                p_confused = d(fake)\n",
    "                # 使用判别器d判断生成器g生成的假图片的概率与真值ones的交叉熵计算损失\n",
    "                g_cost = fluid.layers.sigmoid_cross_entropy_with_logits(p_confused, ones)\n",
    "                g_avg_cost = fluid.layers.mean(g_cost)\n",
    "                # 反向传播更新生成器g的参数\n",
    "                g_avg_cost.backward()\n",
    "                g_optimizer.minimize(g_avg_cost)\n",
    "                g.clear_gradients()\n",
    "                \n",
    "                # 打印输出\n",
    "                if(iteration_num % 100 == 0):\n",
    "                    print('epoch =', epoch, ', batch =', i, ', real_d_loss =', real_avg_cost.numpy(),\n",
    "                     ', fake_d_loss =', fake_avg_cost.numpy(), 'g_loss =', g_avg_cost.numpy())\n",
    "                    show_image_grid(fake.numpy(), BATCH_SIZE, epoch)                             \n",
    "        \n",
    "        # 存储模型\n",
    "        fluid.save_dygraph(g.state_dict(), model_path+'g')\n",
    "        fluid.save_dygraph(g_optimizer.state_dict(), model_path+'g')\n",
    "        fluid.save_dygraph(d.state_dict(), model_path+'d_o_r')\n",
    "        fluid.save_dygraph(real_d_optimizer.state_dict(), model_path+'d_o_r')\n",
    "        fluid.save_dygraph(d.state_dict(), model_path+'d_o_f')\n",
    "        fluid.save_dygraph(fake_d_optimizer.state_dict(), model_path+'d_o_f')\n",
    "\n",
    "train(mnist_generator, epoch_num=100, batch_size=BATCH_SIZE, use_gpu=True) # 10"
   ]
  }
 ]
}